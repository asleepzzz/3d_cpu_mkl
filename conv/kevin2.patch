diff --git a/conv/build.sh b/conv/build.sh
index 3dc39a4..52957d0 100644
--- a/conv/build.sh
+++ b/conv/build.sh
@@ -1,7 +1,7 @@
 #!/bin/sh
 MKLROOT=/opt/intel
 CXXFLAGS=" -std=c++11  "
-LDFLAGS="-Wl,-rpath,/usr/local/lib:$MKLROOT/mkl/lib/intel64:$MKLROOT/lib/intel64 -lmkldnn -L$MKLROOT/mkl/lib/intel64 -L$MKLROOT/lib/intel64  -lmkl_rt -liomp5  "
+LDFLAGS="-Wl,-rpath,/usr/local/lib:$MKLROOT/mkl/lib/intel64:$MKLROOT/lib/intel64 -lmkldnn -L$MKLROOT/mkl/lib/intel64 -L$MKLROOT/lib/intel64   -liomp5  "
 SRC=conv.cpp
 TARGET=conv.exe
 
diff --git a/conv/conv.cpp b/conv/conv.cpp
index d9399b2..ca2bb92 100644
--- a/conv/conv.cpp
+++ b/conv/conv.cpp
@@ -15,6 +15,15 @@ static void rand_vector(float * vec, size_t num){
     if(!inited){ inited = 1; srand (time(NULL));}
     for(i=0;i<num;i++) vec[i] = ((float)(rand()%1000))/1000.0f;
 }
+
+static void increase_vector(float * vec, size_t num){
+    static size_t inited=0;
+    size_t i;
+    if(!inited){ inited = 1; srand (time(NULL));}
+    for(i=0;i<num;i++) vec[i] = i*1.0f;
+}
+
+
 static size_t valid_vector(float *lhs, float *rhs, size_t num, float delta=0.02){
     size_t i;
     size_t err_cnt=0;
@@ -79,12 +88,17 @@ typedef struct {
     size_t h;
     size_t c;
     size_t k;
+    size_t d;
+    size_t fd;
     size_t fx;
     size_t fy;
+    size_t pd;
     size_t px;
     size_t py;
+    size_t sd;
     size_t sx;
     size_t sy;
+    size_t dd;
     size_t dx;
     size_t dy;
     size_t ng;
@@ -101,7 +115,7 @@ static size_t next_config(shape_t *shape){
     size_t py_arr[]={0,1,2,3};
     size_t px_arr[]={0,1,2,3};
     size_t uv_arr[]={1,2,3};
-    size_t d_arr[] ={1,2,3};
+    size_t d_arr[] ={1,2,3}; 
 #endif
 #if 0
     size_t n_arr[] ={2};
@@ -186,21 +200,37 @@ next_cfg:
 
 int main(){
     shape_t shape;
+    //3d
+    shape.d=1;
+    shape.fd=1;
+    shape.pd=0;
+    shape.sd=1;
+    shape.dd=1;
+
+
     printf(" n  w  y  c  k  fx fy px py sx sy dx dy ow oh| fwd     bwd_d     bwd_f\n");
     while(next_config(&shape)){
-        size_t err_cnt,oh,ow;
+        size_t err_cnt,oh,ow,od;
         oh = out_size(shape.h, shape.py, shape.dy, shape.fy, shape.sy);
         ow = out_size(shape.w, shape.px, shape.dx, shape.fx, shape.sx);
+        od = out_size(shape.d, shape.pd, shape.dd, shape.fd, shape.sd);
         printf("%2lu %2lu %2lu %2lu %2lu %2lu %2lu %2lu %2lu %2lu %2lu %2lu %2lu %2lu %2lu ",
             shape.n,shape.w,shape.h,shape.c,shape.k,shape.fx,shape.fy,shape.px,shape.py,shape.sx,shape.sy,shape.dx,shape.dy,ow,oh);
 
-        float * t_input = new float[shape.n*shape.c*shape.h*shape.w];
-        float * t_out = new float[shape.n*shape.k*oh*ow];
-        float * t_filter = new float[shape.k*shape.c*shape.fy*shape.fx];
+        float * t_input = new float[shape.n*shape.c*shape.h*shape.w*shape.d];
+        float * t_out = new float[shape.n*shape.k*oh*ow*od];
+        float * t_filter = new float[shape.k*shape.c*shape.fy*shape.fx*shape.fd];
+
+        float * t_ref = new float[shape.n*shape.k*oh*ow*od];
+        rand_vector(t_input, shape.n*shape.c*shape.h*shape.w*shape.d);
+        rand_vector(t_filter, shape.k*shape.c*shape.fy*shape.fx*shape.fd);
+
+
+
+//3d
+//        mkldnn_conv_fwd_nchw_3d(shape.d,shape.fd,shape.pd,shape.sd,shape.dd,t_input, t_filter, t_out, shape.n,shape.w,shape.h,shape.c,shape.k,shape.fx,shape.fy,shape.px,shape.py,shape.sx,shape.sy,shape.dx,shape.dy);
+//        naive_conv_fwd_nchw_3d(t_input, t_filter, t_ref, shape.n,shape.w,shape.h,shape.c,shape.d,shape.k,shape.fd,shape.fx,shape.fy,shape.pd,shape.px,shape.py,shape.sd,shape.sx,shape.sy,shape.dd,shape.dx,shape.dy);
 
-        float * t_ref = new float[shape.n*shape.k*oh*ow];
-        rand_vector(t_input, shape.n*shape.c*shape.h*shape.w);
-        rand_vector(t_filter, shape.k*shape.c*shape.fy*shape.fx);
         mkldnn_conv_fwd_cnhw(t_input, t_filter, t_out, shape.n,shape.w,shape.h,shape.c,shape.k,shape.fx,shape.fy,shape.px,shape.py,shape.sx,shape.sy,shape.dx,shape.dy);
         naive_conv_fwd_cnhw(t_input, t_filter, t_ref, shape.n,shape.w,shape.h,shape.c,shape.k,shape.fx,shape.fy,shape.px,shape.py,shape.sx,shape.sy,shape.dx,shape.dy);
         err_cnt = valid_vector_rms(t_out, t_ref, shape.n*shape.k*oh*ow);
diff --git a/conv/mkldnn_conv.h b/conv/mkldnn_conv.h
index 15ee63c..a480fb4 100644
--- a/conv/mkldnn_conv.h
+++ b/conv/mkldnn_conv.h
@@ -73,18 +73,25 @@ typedef struct{
     size_t w;
     size_t h;
     size_t c;
+    size_t d;
     size_t k;
+    size_t fd;
     size_t fx;
     size_t fy;
+    size_t pd;
     size_t px;
     size_t py;
+    size_t sd;
     size_t sx;
     size_t sy;
+    size_t dd;
     size_t dx;
     size_t dy;
+    size_t od;
     size_t ow;
     size_t oh;
 
+
     mkldnn::memory::desc *src_desc;
     mkldnn::memory::desc *filter_desc;
     mkldnn::memory::desc *dst_desc;
@@ -170,6 +177,7 @@ static inline void md_conv_init(md_conv_handle *conv,size_t n, size_t w, size_t
     conv->dy = dy;
     conv->ow = md_conv_out_size(w, px, dx, fx, sx);
     conv->oh = md_conv_out_size(h, py, dy, fy, sy);
+
 #if MKLDNN_VERSION_MAJOR >= 1
     conv->src_desc = new mkldnn::memory::desc({(int)n,(int)c,(int)h,(int)w}, mkldnn::memory::data_type::f32, mkldnn::memory::format_tag::nchw);
     conv->filter_desc = new mkldnn::memory::desc({(int)k,(int)c,(int)fy,(int)fx}, mkldnn::memory::data_type::f32, mkldnn::memory::format_tag::oihw);
@@ -207,6 +215,53 @@ static inline void md_conv_init(md_conv_handle *conv,size_t n, size_t w, size_t
                         {(int)sy,(int)sx},{(int)dy-1,(int)dx-1},{(int)py,(int)px},{(int)py,(int)px},mkldnn::padding_kind::zero);
 #endif
 }
+
+static inline void md_conv_init_3d(md_conv_handle *conv,size_t n,size_t d,size_t fd,size_t pd,size_t sd,size_t dd, size_t w, size_t h, size_t c, size_t k, size_t fx, size_t fy, size_t px, size_t py, size_t sx, size_t sy, size_t dx, size_t dy){
+    conv->n = n;
+    conv->w = w;
+    conv->h = h;
+    conv->c = c;
+    conv->k = k;
+    conv->d = d;
+    conv->fd = fd;
+    conv->fx = fx;
+    conv->fy = fy;
+    conv->pd = pd;
+    conv->px = px;
+    conv->py = py;
+    conv->sd = sd;
+    conv->sx = sx;
+    conv->sy = sy;
+    conv->dd = dd;
+    conv->dx = dx;
+    conv->dy = dy;
+    conv->od = md_conv_out_size(d, pd, dd, fd, sd);
+    conv->ow = md_conv_out_size(w, px, dx, fx, sx);
+    conv->oh = md_conv_out_size(h, py, dy, fy, sy);
+    conv->src_desc = new mkldnn::memory::desc({(int)n,(int)c,(int)d,(int)h,(int)w}, mkldnn::memory::data_type::f32, mkldnn::memory::format_tag::ncdhw);
+
+    conv->filter_desc = new mkldnn::memory::desc({(int)k,(int)c,(int)fd,(int)fy,(int)fx}, mkldnn::memory::data_type::f32, mkldnn::memory::format_tag::oidhw);
+
+    conv->dst_desc = new mkldnn::memory::desc({(int)n,(int)k,(int)conv->od,(int)conv->oh,(int)conv->ow}, mkldnn::memory::data_type::f32, mkldnn::memory::format_tag::ncdhw);
+
+
+    conv->fwd_desc = new mkldnn::convolution_forward::desc(mkldnn::prop_kind::forward,
+                        mkldnn::algorithm::convolution_direct,
+                        *conv->src_desc,*conv->filter_desc,*conv->dst_desc,
+                        {(int)1,(int)sy,(int)sx},{(int)0,(int)dy-1,(int)dx-1},{(int)0,(int)py,(int)px},{(int)0,(int)py,(int)px});
+    // note in mkl-dnn, dilation is 0 when unit dilation.
+
+    conv->bwd_d_desc = new mkldnn::convolution_backward_data::desc(mkldnn::algorithm::convolution_direct,
+                        *conv->src_desc,*conv->filter_desc,*conv->dst_desc,
+                        {(int)1,(int)sy,(int)sx},{int(0),(int)dy-1,(int)dx-1},{(int)0,(int)py,(int)px},{(int)0,(int)py,(int)px});
+ 
+    conv->bwd_f_desc = new mkldnn::convolution_backward_weights::desc(mkldnn::algorithm::convolution_direct,
+                        *conv->src_desc,*conv->filter_desc,*conv->dst_desc,
+                        {(int)1,(int)sy,(int)sx},{(int)0,(int)dy-1,(int)dx-1},{(int)0,(int)py,(int)px},{(int)0,(int)py,(int)px});
+
+}
+
+
 static inline void md_conv_destroy(md_conv_handle * conv){
     delete conv->src_desc;
     delete conv->filter_desc;
@@ -241,6 +296,35 @@ static inline void md_conv_fwd_nchw(md_handle *mh, md_conv_handle *conv, float *
 #endif
 }
 
+
+static inline void md_conv_fwd_nchw_3d(md_handle *mh, md_conv_handle *conv, float * src, float * filter, float * dst){
+#if MKLDNN_VERSION_MAJOR >= 1
+    auto src_memory = mkldnn::memory( *conv->src_desc,*mh->eng);
+    auto filter_memory = mkldnn::memory(*conv->filter_desc, *mh->eng);
+    auto dst_memory = mkldnn::memory(*conv->dst_desc, *mh->eng);
+
+    write_to_mkldnn_memory(src, src_memory);
+    write_to_mkldnn_memory(filter, filter_memory);
+
+    mkldnn::convolution_forward conv_fwd({*conv->fwd_desc, *mh->eng});
+
+    auto stream = mkldnn::stream(*mh->eng);
+    conv_fwd.execute(stream, {{MKLDNN_ARG_SRC, src_memory},
+                                {MKLDNN_ARG_WEIGHTS, filter_memory},
+                                {MKLDNN_ARG_DST, dst_memory}});
+    stream.wait();
+    read_from_mkldnn_memory(dst, dst_memory);
+#else
+    auto src_memory = mkldnn::memory( {*conv->src_desc,*mh->eng}, src  );
+    auto filter_memory = mkldnn::memory({*conv->filter_desc, *mh->eng}, filter  );
+    auto dst_memory = mkldnn::memory({*conv->dst_desc, *mh->eng}, dst);
+    mkldnn::convolution_forward conv_fwd({*conv->fwd_desc,*mh->eng},src_memory,filter_memory,dst_memory  );
+    mkldnn::stream(mkldnn::stream::kind::eager).submit({conv_fwd}).wait();
+#endif
+}
+
+
+
 static inline void md_conv_fwd_cnhw(md_handle *mh, md_conv_handle *conv, float * src, float * filter, float * dst){
     int n = conv->src_desc->data.dims[0];
     int c = conv->src_desc->data.dims[1];
@@ -252,6 +336,7 @@ static inline void md_conv_fwd_cnhw(md_handle *mh, md_conv_handle *conv, float *
     float * src_nchw = new float[n*c*h*w];
     float * dst_nchw = new float[n*k*oh*ow];
     md_conv_cnhw_2_nchw(src_nchw, src, n, c, h, w);
+
 #if MKLDNN_VERSION_MAJOR >= 1
     auto stream = mkldnn::stream(*mh->eng);
 
@@ -280,6 +365,9 @@ static inline void md_conv_fwd_cnhw(md_handle *mh, md_conv_handle *conv, float *
     delete [] src_nchw;
     delete [] dst_nchw;
 }
+
+
+
 static inline void md_conv_bwd_d_nchw(md_handle *mh, md_conv_handle *conv, float * src_grad, float * filter, float * dst_grad){
 #if MKLDNN_VERSION_MAJOR >= 1
     auto stream = mkldnn::stream(*mh->eng);
@@ -424,7 +512,22 @@ static inline void md_conv_bwd_f_cnhw(md_handle *mh, md_conv_handle *conv, float
         md_destroy(&md_h);                                                          \
     }
 
+#define MKLDNN_3D_CONV_WARP(dir, layout)                                               \
+    static inline void mkldnn_conv_ ## dir ## _ ## layout (size_t d,size_t fd,size_t pd,size_t sd,size_t dd,float *ts, \
+    float *tf, float *td, size_t n, size_t w, size_t h, size_t c, size_t k, size_t fx, size_t fy, size_t px, size_t py, size_t sx, \
+    size_t sy, size_t dx, size_t dy) \
+    {                                                                               \
+        md_handle md_h;                                                             \
+        md_conv_handle md_conv_h;                                                   \
+        md_init(&md_h);                                                             \
+        md_conv_init_3d(&md_conv_h,n,d,fd,pd,sd,dd,w,h,c,k,fx,fy,px,py,sx,sy,dx,dy);                 \
+        md_conv_## dir ## _ ## layout (&md_h, &md_conv_h, ts, tf, td);              \
+        md_conv_destroy(&md_conv_h);                                                \
+        md_destroy(&md_h);                                                          \
+    }
+
 MKLDNN_CONV_WARP(fwd, nchw)
+MKLDNN_3D_CONV_WARP(fwd, nchw_3d)
 MKLDNN_CONV_WARP(fwd, cnhw)
 MKLDNN_CONV_WARP(bwd_d, nchw)
 MKLDNN_CONV_WARP(bwd_d, cnhw)
diff --git a/conv/naive_conv.h b/conv/naive_conv.h
index 510ddb5..eb2102c 100644
--- a/conv/naive_conv.h
+++ b/conv/naive_conv.h
@@ -37,6 +37,49 @@ static inline void naive_conv_fwd_nchw(const float *src, const float *filter, fl
         }
     }
 }
+
+static inline void naive_conv_fwd_nchw_3d(const float *src, const float *filter, float *dst,
+    size_t n, size_t w, size_t h, size_t c, size_t d,size_t k, size_t fd,size_t fx, size_t fy, size_t pd, size_t px, size_t py,size_t sd, size_t sx, size_t sy,size_t dd, size_t dx, size_t dy)
+{
+    size_t in,ik,iod,ioh,iow,ic,id,is,ir;
+    size_t cur_d,cur_h, cur_w, o_idx, i_idx, f_idx;
+    size_t oh = naive_conv_out_size(h, py, dy, fy, sy);
+    size_t ow = naive_conv_out_size(w, px, dx, fx, sx);
+    size_t od = naive_conv_out_size(d, pd, dd, fd, sd);
+    for(in=0;in<n;in++){
+        for(ik=0;ik<k;ik++){
+            for(iod=0;iod<od;iod++){
+                for(ioh=0;ioh<oh;ioh++){
+                    for(iow=0;iow<ow;iow++){
+                    // sliding window for this filter
+                        float value = .0f;
+                        o_idx = in*k*od*oh*ow+ik*od*oh*ow+iod*oh*ow+ioh*ow+iow;
+                        for(ic=0;ic<c;ic++){
+                            for(id=0;id<fd;id++){
+                                cur_d = sd*iod-pd+dd*id;
+                                if(cur_d<0 || cur_d>=d) continue;
+                                for(ir=0;ir<fy;ir++){
+                                    cur_h = sy*ioh-py+dy*ir;
+                                    if(cur_h<0 || cur_h>=h) continue;
+                                    for(is=0;is<fx;is++){
+                                        cur_w = sx*iow-px+dx*is;
+                                        if(cur_w<0 || cur_w>=w) continue;
+                                        i_idx = in*c*d*h*w+ic*d*h*w+cur_d*h*w+cur_h*w+cur_w;
+                                        f_idx = ik*c*fd*fy*fx+ic*fd*fy*fx+id*fx*fy+ir*fx+is;
+                                        value += src[i_idx]*filter[f_idx];
+                                    }
+                                }
+                            }
+                        }
+                        dst[o_idx] = value;
+                    }
+                }
+            }
+        }
+    }
+}
+
+
 static inline void naive_conv_fwd_cnhw(const float *src, const float *filter, float *dst,
     size_t n, size_t w, size_t h, size_t c, size_t k, size_t fx, size_t fy, size_t px, size_t py, size_t sx, size_t sy, size_t dx, size_t dy)
 {
